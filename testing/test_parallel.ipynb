{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_distance(d, centroids):\n",
    "    \"\"\"\n",
    "    function return the minimum distance from point d to nearest centroids\n",
    "    \"\"\"\n",
    "    dist = np.min(np.sum((centroids - d)**2, axis=1))\n",
    "    return dist\n",
    "\n",
    "def cost_p(data, centroids): \n",
    "    \"\"\"\n",
    "    function that return the cost(distance) for each observation\n",
    "    \"\"\"\n",
    "\n",
    "    with mp.Pool(processes = mp.cpu_count()) as pool:\n",
    "        partial_dist = partial(min_distance, centroids = centroids)\n",
    "        min_dist = pool.map(partial_dist, data)\n",
    "        p = min_dist/np.sum(min_dist)\n",
    "    return p\n",
    "\n",
    "\n",
    "def random_choice(x, a, p):\n",
    "    \"\"\"\n",
    "    helper function like np.random.choice\n",
    "    but have one less argument and shift order of arguments for future map\n",
    "    \"\"\"\n",
    "    np.random.seed()\n",
    "    return np.random.choice(a = a, size = x , p =p)\n",
    "\n",
    "\n",
    "def sample_p(data, distribution, l):\n",
    "    \n",
    "    \"\"\" \n",
    "    Function to sample l number new centers\n",
    "    \"\"\"  \n",
    "    \n",
    "    with mp.Pool(processes = mp.cpu_count()) as pool:\n",
    "        partial_rc = partial(random_choice, a = len(distribution), p=distribution)\n",
    "        #create l number of size one observation\n",
    "        index = pool.map(partial_rc,np.repeat(1,l))\n",
    "    return np.squeeze(data[index,:],axis=(1,))\n",
    "\n",
    "\n",
    "def min_index_p(d, centroids):\n",
    "    \n",
    "    \"\"\" \n",
    "    Return the index of the minimum distance from point d \n",
    "    to its nearest centroids.\n",
    "    \"\"\"\n",
    "    \n",
    "    index = np.argmin(np.sum((centroids - d)**2, axis=1))\n",
    "    return index \n",
    "\n",
    "def get_weight_p(data, centroids):\n",
    "    \n",
    "    ''' \n",
    "        Function to return  weight for each centorid\n",
    "        Input: data, an array of data. centroids, initial centroids\n",
    "        Output: C, an array with length k of weight for cluster centers. \n",
    "    '''\n",
    "\n",
    "    with mp.Pool(processes = mp.cpu_count()) as pool:\n",
    "        partial_min = partial(min_index_p, centroids = centroids )\n",
    "        min_index = pool.map(partial_min, data)\n",
    "        count = np.array([np.sum(np.array(min_index) == i) for i in range(centroids.shape[0])])\n",
    "    return count/np.sum(count)\n",
    "\n",
    "\n",
    "\n",
    "def cdist_kmeans_pp(data, k, weights):\n",
    "    ''' \n",
    "        Function to return final centers for the using k-means++ clustering algorithm\n",
    "        Input: data, an array of data. k, the number of clusters. weights, weight for each initial centroids\n",
    "        Output: C, an array with length k of initial cluster centers. \n",
    "    '''\n",
    "    first_random = np.random.choice(data.shape[0], 1)\n",
    "    C = data[first_random, :]\n",
    "    \n",
    "    for i in range(k-1):\n",
    "        cdist = (dist.cdist(data, C))**2\n",
    "        cdist_min = np.min(cdist, axis = 1)* weights\n",
    "        prob = cdist_min/np.sum(cdist_min)\n",
    "        new_center = np.random.choice(data.shape[0],1, p=prob)\n",
    "        C = np.vstack([C, data[new_center,:]])\n",
    "        \n",
    "    return C\n",
    "\n",
    "def kmeans_II_p(data, k, l):\n",
    "    ''' \n",
    "        Function to return final centers for the using k-means|| clustering algorithm\n",
    "        Input: data, an array of data. k, the number of clusters. l, oversampling factor\n",
    "        Output: C, an array with length k of initial cluster centers. \n",
    "    '''\n",
    "    \n",
    "    C = data[np.random.choice(range(data.shape[0]),1), :]  \n",
    "    cdist = (dist.cdist(data, C))**2\n",
    "    cdist_min = np.min(cdist, axis = 1)\n",
    "    cost_phi = np.sum(cdist_min)\n",
    "    \n",
    "    for i in range(int(round(np.log(cost_phi)))):   \n",
    "        \n",
    "        # Calculate the cost and new distribution\n",
    "        p = cost_p(data, C)\n",
    "        \n",
    "        # sample new centers\n",
    "        C = np.r_[C, sample_p(data, p, l)]\n",
    "        \n",
    "    weights = get_weight_p(data,C)\n",
    "    \n",
    "    centers = cdist_kmeans_pp(C, k, weights)\n",
    "    \n",
    "    return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "spambase = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\", header=None)\n",
    "df = np.array(spambase)\n",
    "k = 20\n",
    "l = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 58)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_II_p(df, k, l).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    " x = np.array([[[0], [1], [2]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomSample(x, a, p):\n",
    "    np.random.seed()\n",
    "    return np.random.choice(a = a, size = x , p =p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_new_p(data, dist, l):\n",
    "        \n",
    "    with mp.Pool(processes = mp.cpu_count()) as pool:\n",
    "        #partial_rc = partial(randomSample, a = len(distribution), p=distribution)\n",
    "        index = pool.starmap(randomSample, [[[1]*l], [len(dist)], [dist]])\n",
    "        #index = pool.map(partial_rc,[1]*l)\n",
    "    return np.squeeze(data[index,:],axis=(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    " with mp.Pool(processes = mp.cpu_count()) as pool:\n",
    "        #partial_rc = partial(randomSample, a = len(distribution), p=distribution)\n",
    "        index = pool.starmap(np.random.choice, [[a,3],[b,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([2, 9, 1]), array([165, 140, 130, 196])]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(1,10)\n",
    "b = np.arange(100,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "       0.11111111, 0.11111111, 0.11111111, 0.11111111])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.repeat(1/9,9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
